{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "pd.set_option(\"max_columns\",100)\n",
    "\n",
    "DATA_DIR=\"./Data/OnlineNewsPopularity/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(DATA_DIR+\"OnlineNewsPopularity.csv\")\n",
    "meta=pd.read_csv(\"Articles_meta.csv\")\n",
    "body=pd.read_csv(\"Articles_body.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=pd.read_csv(DATA_DIR+\"files.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(meta.values[13])\n",
    "print(body.values[0])\n",
    "df.iloc[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=meta.values[:5,1]\n",
    "contents=body.values[:5,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "from textblob import TextBlob\n",
    "\n",
    "vader=SentimentIntensityAnalyzer()\n",
    "\n",
    "stopw=set(stopwords.words('english'))\n",
    "for index,(title_s, content_s) in enumerate(zip(sentences, contents), start=1):\n",
    "    sentiment_l=[]\n",
    "    non_stop_w=[]\n",
    "    wordlen=0\n",
    "    print(index)\n",
    "    \n",
    "    title=re.findall(r'\\w+', title_s)\n",
    "    content=re.findall(r'\\w+', content_s)\n",
    "    for word in content:\n",
    "        sentiment_l.append(vader.polarity_scores(word))\n",
    "        sentiment_l[-1].update(dict(TextBlob(word).sentiment._asdict()))\n",
    "        wordlen+=len(word)\n",
    "        if word not in stopw:\n",
    "            non_stop_w.append(word)\n",
    "    sentiment_df=pd.DataFrame(sentiment_l)\n",
    "    print(len(title), len(content))\n",
    "    print(len(np.unique(title)), len(np.unique(content))/len(content))\n",
    "    non_stop_w=[i for i in content if i not in stopw]\n",
    "    print(len(non_stop_w), len(np.unique(non_stop_w))/len(non_stop_w))\n",
    "    wordlen=sum([len(word) for word in content])/len(content)\n",
    "    print(wordlen)\n",
    "    print(TextBlob(content_s).sentiment)\n",
    "    print(TextBlob(title_s).sentiment)\n",
    "    polarity=\n",
    "    print(vader.polarity_scores(content_s))\n",
    "    print(vader.polarity_scores(title_s))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=meta[meta['Title'].isnull()].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload  \n",
    "import preprocess\n",
    "from pandarallel import pandarallel\n",
    "reload(preprocess)\n",
    "\n",
    "pandarallel.initialize()\n",
    "\n",
    "def preproc(row):\n",
    "    try:\n",
    "        with open(\"./Data/OnlineNewsPopularity/mashable/%s\"%row.file, \"r\") as f:\n",
    "            ret_d={'url':row.url}\n",
    "            ret_d.update(preprocess.Article(row.url, f.read()).stats())\n",
    "            return ret_d\n",
    "    except Exception as e:\n",
    "        print(e, row.file, row.url)\n",
    "        return None\n",
    "df=files.parallel_apply(preproc, axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df_preprocessed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=pd.read_csv(\"df_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for file in files:\n",
    "    try:\n",
    "        with open(\"./Data/OnlineNewsPopularity/mashable/%d.html\"%file, \"r\") as f:\n",
    "            px=preprocess.Article(meta['url'][1], f.read())\n",
    "            print(px.stats())\n",
    "    except Exception as e:\n",
    "        count+=1\n",
    "        print(file, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "title=re.findall(r'\\w+', sentences[1])\n",
    "len(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "f=open(\"./Data/OnlineNewsPopularity/mashable/11.html\", \"r\")\n",
    "soup=BeautifulSoup(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "title_l=[ (\"meta\", {\"property\": re.compile(\"title.*\")}), (\"mega\", {\"property\": re.compile(\".*title.*\")}), (\"meta\", {\"property\": re.compile(\".*title.*\")})]\n",
    "\n",
    "for args in title_l:\n",
    "\n",
    "    title=soup.find(*args)\n",
    "    if title:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=soup.find(\"section\").findAll(\"a\", href=True)\n",
    "x[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(soup.find(\"article\").findAll(\"iframe\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len((\" \".join(list(soup.find('section').stripped_strings)).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
